# Neural_Accleration_Lab
모두의 연구소에서 진행하는 Neural Acceleration Lab의 git 입니다. 

본 Lab에서 발표하는 논문 리스트는 다음과 같습니다.

|  <center>번호</center> |  <center>논문명</center> | <center>학회</center> | <center>분야</center> | <center>출판일</center> |
|:--------:|:--------:|:--------:|:--------:|:--------:|
|<center>1</center> | <center>Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism</center> | <center>ISCA</center> | <center>Pruning</center>|<center>2017</center>|
|<center>2</center> | <center>Diagonalwise Refactorization: An Efficient Training Method for Depthwise Convolutions</center> |IJCNN | Algorithm | 2018 |
|<center>3</center> | Optimal DNN Primitive Selection with Partitioned Boolean quadratic Programming |CGO | Primitive Selection | 2018 |
|<center>4</center> | Co-Design of Deep Neural Nets and Neural Net Accelerators for Embedded Vision Applications |DAC | NPU | 2018 |
|<center>5</center> | µLayer:Low Latency On-Device Inference Using Cooperative Single-Layer Acceleration and Processor-Friendly Quantization |EuroSys | CPU+GPU | 2019 |
|<center>6</center> | Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge |ASPLOS | Edge+Server | 2017 |
|<center>7</center> | TSM2: Optimizing Tall-and-Skinny Matrix-Matrix Multiplication on GPUs |ICS | Irregular GEMM | 2019 |
|<center>8</center> | Sparse Tensor Core: Algorithm and Hardware Co-Design for Vector-wise Sparse Neural Networks on Modern GPUs |Micro | Tensor Core | 2019 |
|<center>9</center> | EFFICIENT WINOGRAD CONVOLUTION VIA INTEGER ARITHMETIC |Arxiv | Algorithm | 2019 |
|<center>10</center> | Optimizing CNN Model Inference on CPUs |Usenix | ? | 2019 |
|<center>11</center> | Machine Learning at Facebook: Understanding Inference at the Edge |HPCA | Overview Paper | 2019 |
|<center>12</center> | Rethinking floating point for deep learning |NIPS | Algorithm | 2018 |
|<center>13</center> | Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications |Arxiv | Overview Paper | 2018 |
|<center>14</center> | EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks |CVPR | Neural Network | 2019 |




